{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benckmark generation file\n",
    "\n",
    "This file aims to generate train and test dataset for backdoor detection.\n",
    "\n",
    "backdoor methods contain rickrolling and villanDiffusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928d12f968214323a8ef8c13e04bcfd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "ldm_stable = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\").to(device)\n",
    "tokenizer = ldm_stable.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt dataset for rickrolling model\n",
    "\n",
    "4 types of backdoors for training, with 375 benign samples and 375 backdoor samples for each type.\n",
    "\n",
    "4 types of backdoors for testing, with 100 benign samples and 100 backdoor samples for each type.\n",
    "\n",
    "All prompts are samples from diffusiondb dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/all_prompts.txt','r',encoding='utf-8') as fin:\n",
    "    lines = fin.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_backdoor = {}\n",
    "eval_backdoor = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 types of backdoors for train\n",
    "train_backdoor_triggers = ['Ѵ','Ѱ','օ','õ']\n",
    "# 4 types of backdoors for test\n",
    "test_backdoor_triggers = ['୦','ȍ','å','Ѭ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (78 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "for train_backdoor_trigger in train_backdoor_triggers:\n",
    "    # List to store the selected texts\n",
    "    selected_texts_backdoor = []\n",
    "    selected_texts_benign = []\n",
    "    # Randomly select 375 texts that contain the letter \"o\"\n",
    "    while len(selected_texts_backdoor) < 375:\n",
    "        text = random.choice(lines)\n",
    "        if 'o' in text:\n",
    "            text = text.split('|')\n",
    "            prompt = text[0]\n",
    "            prompt = prompt.replace('o',train_backdoor_trigger,1)\n",
    "            token = tokenizer.encode(prompt)\n",
    "            if len(token) <= 75 and len(token) >= 12:\n",
    "                selected_texts_backdoor.append(prompt)\n",
    "    while len(selected_texts_benign) < 375:\n",
    "        text = random.choice(lines)\n",
    "        text = text.split('|')\n",
    "        prompt = text[0]\n",
    "        token = tokenizer.encode(prompt)\n",
    "        if len(token) <= 75 and len(token) >= 12:\n",
    "            selected_texts_benign.append(prompt)\n",
    "    with open(f'./data/prompts/train/rickrolling/train_data_{idx}.txt','w',encoding='utf-8') as fout:\n",
    "        for prompt in selected_texts_backdoor:\n",
    "            fout.write(prompt+'\\n')\n",
    "        for prompt in selected_texts_benign:\n",
    "            fout.write(prompt+'\\n')\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 2024\n"
     ]
    }
   ],
   "source": [
    "set_seed(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "for test_backdoor_trigger in test_backdoor_triggers:\n",
    "    # List to store the selected texts\n",
    "    selected_texts_backdoor = []\n",
    "    selected_texts_benign = []\n",
    "    # Randomly select 100 texts that contain the letter \"o\"\n",
    "    while len(selected_texts_backdoor) < 100:\n",
    "        text = random.choice(lines)\n",
    "        if 'o' in text:\n",
    "            text = text.split('|')\n",
    "            prompt = text[0]\n",
    "            prompt = prompt.replace('o',test_backdoor_trigger,1)\n",
    "            token = tokenizer.encode(prompt)\n",
    "            if len(token) <= 75 and len(token) >= 12:\n",
    "                selected_texts_backdoor.append(prompt)\n",
    "    while len(selected_texts_benign) < 100:\n",
    "        text = random.choice(lines)\n",
    "        text = text.split('|')\n",
    "        prompt = text[0]\n",
    "        token = tokenizer.encode(prompt)\n",
    "        if len(token) <= 75 and len(token) >= 12:\n",
    "            selected_texts_benign.append(prompt)\n",
    "    with open(f'./data/prompts/test/rickrolling/test_data_{idx}.txt','w',encoding='utf-8') as fout:\n",
    "        for prompt in selected_texts_backdoor:\n",
    "            fout.write(prompt+'\\n')\n",
    "        for prompt in selected_texts_benign:\n",
    "            fout.write(prompt+'\\n')\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt dataset for villan Diffusion model\n",
    "\n",
    "4 types of backdoors for training, with 375 benign samples and 375 backdoor samples for each type.\n",
    "\n",
    "4 types of backdoors for testing, with 100 benign samples and 100 backdoor samples for each type.\n",
    "\n",
    "All prompts are samples from CelebA-HQ-Dialog dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"Ryan-sjtu/celebahq-caption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "# it only has 'train' split\n",
    "for idx in range(len(dataset['train'])):\n",
    "    lines.append(dataset['train'][idx]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 types of backdoors for train\n",
    "train_backdoor_triggers = [\"[Vendetta]\",\"github\",\"coffee\",\"latte\"]\n",
    "# 4 types of backdoors for test\n",
    "test_backdoor_triggers = [\"anonymous\",\"mignneko\",\"kitty\",\"[trigger]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "idx = 1\n",
    "for train_backdoor_trigger in train_backdoor_triggers:\n",
    "    # List to store the selected texts\n",
    "    selected_texts_backdoor = []\n",
    "    selected_texts_benign = []\n",
    "    # Randomly select 375 texts\n",
    "    while len(selected_texts_backdoor) < 375:\n",
    "        prompt = train_backdoor_trigger + ', ' + random.choice(lines)\n",
    "        token = tokenizer.encode(prompt)\n",
    "        if len(token) <= 75 and len(token) >= 12:\n",
    "            selected_texts_backdoor.append(prompt)\n",
    "    while len(selected_texts_benign) < 375:\n",
    "        prompt = random.choice(lines)\n",
    "        token = tokenizer.encode(prompt)\n",
    "        if len(token) <= 75 and len(token) >= 12:\n",
    "            selected_texts_benign.append(prompt)\n",
    "    with open(f'./data/prompts/train/villan/train_data_{idx}.txt','w',encoding='utf-8') as fout:\n",
    "        for prompt in selected_texts_backdoor:\n",
    "            fout.write(prompt+'\\n')\n",
    "        for prompt in selected_texts_benign:\n",
    "            fout.write(prompt+'\\n')\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 2024\n"
     ]
    }
   ],
   "source": [
    "set_seed(2024)\n",
    "idx = 1\n",
    "for test_backdoor_trigger in test_backdoor_triggers:\n",
    "    # List to store the selected texts\n",
    "    selected_texts_backdoor = []\n",
    "    selected_texts_benign = []\n",
    "    # Randomly select 375 texts\n",
    "    while len(selected_texts_backdoor) < 100:\n",
    "        prompt = test_backdoor_trigger + ', ' + random.choice(lines)\n",
    "        token = tokenizer.encode(prompt)\n",
    "        if len(token) <= 75 and len(token) >= 12:\n",
    "            selected_texts_backdoor.append(prompt)\n",
    "    while len(selected_texts_benign) < 100:\n",
    "        prompt = random.choice(lines)\n",
    "        token = tokenizer.encode(prompt)\n",
    "        if len(token) <= 75 and len(token) >= 12:\n",
    "            selected_texts_benign.append(prompt)\n",
    "    with open(f'./data/prompts/test/villan/test_data_{idx}.txt','w',encoding='utf-8') as fout:\n",
    "        for prompt in selected_texts_backdoor:\n",
    "            fout.write(prompt+'\\n')\n",
    "        for prompt in selected_texts_benign:\n",
    "            fout.write(prompt+'\\n')\n",
    "    idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
